<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>nlp on Home</title><link>https://antopolskiy.github.io/tags/nlp/</link><description>Recent content in nlp on Home</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 22 Oct 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://antopolskiy.github.io/tags/nlp/index.xml" rel="self" type="application/rss+xml"/><item><title>Kickstart text classification with GPT-3, part 2</title><link>https://antopolskiy.github.io/post/gpt3_2/</link><pubDate>Sat, 22 Oct 2022 00:00:00 +0000</pubDate><guid>https://antopolskiy.github.io/post/gpt3_2/</guid><description>Where we stopped In the previous part we finished with the desire to get predictions for multiple samples and multiple categories. We will do it here using a Markdown table format.
What is Markdown? Markdown is a lightweight markup language that you can use to add formatting elements to plaintext text documents. Created by John Gruber in 2004, Markdown is now one of the world’s most popular markup languages.
Basically, Markdown is a way to specify formatting in a plain text document, using special symbols.</description></item><item><title>Kickstart text classification with GPT-3, part 1</title><link>https://antopolskiy.github.io/post/gpt3_1/</link><pubDate>Sat, 01 Oct 2022 00:00:00 +0000</pubDate><guid>https://antopolskiy.github.io/post/gpt3_1/</guid><description>Motivation In the life of any data scientist there comes a point when they need to train a baseline classification model for some task, but don&amp;rsquo;t have labelled data to start. In this series of posts, I propose an approach to get labelled data for text classification using large pretrained neural networks, such as GPT-3. This approach will help you kickstart your classification problem.
TL;DR Gives a brief introduction to GPT-3; discusses a way to think about text completion; explains what is zero-shot, few-show classification and fine-tuning; introduces the example dataset that will be used in this series of posts; gives several examples of a naive approach to completion.</description></item></channel></rss>